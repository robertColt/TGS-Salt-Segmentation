{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"unet_resnet_101_adam_lovasz-loss_iou-metric.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1565693008884,"user_tz":-180,"elapsed":4186,"user":{"displayName":"Robert-George Colt","photoUrl":"","userId":"03778483518713272755"}},"id":"Zl27ZuATowVG","outputId":"fa1b20aa-73bd-422f-91f9-d0584f66e222","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cI-rlUbLICuH","colab":{}},"source":["from keras.layers import Conv2D, MaxPooling2D, Input, Activation, Conv2DTranspose, concatenate, BatchNormalization, Add, Dropout\n","from keras.models import Model,load_model\n","from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n","from keras.optimizers import Adam, SGD\n","from keras import backend as K\n","\n","import tensorflow as tf\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Sv0dj5PmpMc_","colab":{}},"source":["x_train = np.load('/content/drive/My Drive/Kaggle/TGS-Salt-Segmentation/data/101/all_samples/x_train.npy')\n","x_valid = np.load('/content/drive/My Drive/Kaggle/TGS-Salt-Segmentation/data/101/all_samples/x_valid.npy')\n","y_train = np.load('/content/drive/My Drive/Kaggle/TGS-Salt-Segmentation/data/101/all_samples/y_train.npy')\n","y_valid = np.load('/content/drive/My Drive/Kaggle/TGS-Salt-Segmentation/data/101/all_samples/y_valid.npy')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"--RoaZVXoKNg","colab":{}},"source":["def get_iou_vector(A, B):\n","    batch_size = A.shape[0]\n","    metric = []\n","    for batch in range(batch_size):\n","        t, p = A[batch]>0, B[batch]>0\n","        \n","        intersection = np.logical_and(t, p)\n","        union = np.logical_or(t, p)\n","        iou = (np.sum(intersection > 0) + 1e-10 )/ (np.sum(union > 0) + 1e-10)\n","        thresholds = np.arange(0.5, 1, 0.05)\n","        s = []\n","        for thresh in thresholds:\n","            s.append(iou > thresh)\n","        metric.append(np.mean(s))\n","        \n","    return np.mean(metric)\n","        \n","def iou2(label, pred):\n","    return tf.py_func(get_iou_vector, [label, pred > 0], tf.float64)\n","  \n","  \n","def lovasz_grad(gt_sorted):\n","    \"\"\"\n","    Computes gradient of the Lovasz extension w.r.t sorted errors\n","    See Alg. 1 in paper\n","    \"\"\"\n","    gts = tf.reduce_sum(gt_sorted)\n","    intersection = gts - tf.cumsum(gt_sorted)\n","    union = gts + tf.cumsum(1. - gt_sorted)\n","    jaccard = 1. - intersection / union\n","    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n","    return jaccard\n","\n","\n","# --------------------------- BINARY LOSSES ---------------------------\n","\n","def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n","    \"\"\"\n","    Binary Lovasz hinge loss\n","      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n","      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n","      per_image: compute the loss per image instead of per batch\n","      ignore: void class id\n","    \"\"\"\n","    if per_image:\n","        def treat_image(log_lab):\n","            log, lab = log_lab\n","            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n","            log, lab = flatten_binary_scores(log, lab, ignore)\n","            return lovasz_hinge_flat(log, lab)\n","        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n","        loss = tf.reduce_mean(losses)\n","    else:\n","        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n","    return loss\n","\n","\n","def lovasz_hinge_flat(logits, labels):\n","    \"\"\"\n","    Binary Lovasz hinge loss\n","      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n","      labels: [P] Tensor, binary ground truth labels (0 or 1)\n","      ignore: label to ignore\n","    \"\"\"\n","\n","    def compute_loss():\n","        labelsf = tf.cast(labels, logits.dtype)\n","        signs = 2. * labelsf - 1.\n","        errors = 1. - logits * tf.stop_gradient(signs)\n","        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n","        gt_sorted = tf.gather(labelsf, perm)\n","        grad = lovasz_grad(gt_sorted)\n","        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n","        return loss\n","\n","    # deal with the void prediction case (only void pixels)\n","    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n","                   lambda: tf.reduce_sum(logits) * 0.,\n","                   compute_loss,\n","                   strict=True,\n","                   name=\"loss\"\n","                   )\n","    return loss\n","\n","\n","def flatten_binary_scores(scores, labels, ignore=None):\n","    \"\"\"\n","    Flattens predictions in the batch (binary case)\n","    Remove labels equal to 'ignore'\n","    \"\"\"\n","    scores = tf.reshape(scores, (-1,))\n","    labels = tf.reshape(labels, (-1,))\n","    if ignore is None:\n","        return scores, labels\n","    valid = tf.not_equal(labels, ignore)\n","    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n","    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n","    return vscores, vlabels\n","\n","def lovasz_loss(y_true, y_pred):\n","    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n","    #logits = K.log(y_pred / (1. - y_pred))\n","    logits = y_pred #Jiaxin\n","    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n","    return loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5oUnEol0I7A6","colab":{}},"source":["def batch_activation(x):\n","  x = BatchNormalization()(x)\n","  x = Activation('relu')(x)\n","  return x\n","  \n","def conv2d_block(input_tensor, n_filters, kernel_size=(3,3), activation=True):\n","    # first layer\n","    c1 = Conv2D(filters=n_filters, kernel_size=kernel_size, kernel_initializer=\"he_normal\",\n","               padding=\"same\")(input_tensor)\n","    if activation:\n","      c1 = batch_activation(c1)\n","    return c1\n","\n","  \n","def residual_block(input_tensor, num_filters=16, batch_activate = False):\n","    x = batch_activation(input_tensor)\n","    x = conv2d_block(x, num_filters, (3,3))\n","    x = conv2d_block(x, num_filters, (3,3), activation=False)\n","    x = Add()([x, input_tensor])\n","    if batch_activate:\n","        x = batch_activation(x)\n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IRmQxYlfJCUO","colab":{}},"source":["def unet_resnet_model():\n","    inputs = Input((101,101,1))\n","\n","    #   101 -> 50\n","    filters = 16\n","    c1 = Conv2D(filters=filters, kernel_size=(3, 3), activation=None, padding=\"same\")(inputs)\n","    print(type(c1))\n","    c1 = residual_block(c1, filters)\n","    c1 = residual_block(c1, filters, batch_activate=True)\n","    p1 = MaxPooling2D((2,2))(c1)\n","\n","    #   50 -> 25\n","    filters = 32\n","    c2 = Conv2D(filters, (3, 3), activation=None, padding=\"same\")(p1)\n","    c2 = residual_block(c2, filters)\n","    c2 = residual_block(c2, filters, batch_activate=True)\n","    p2 = MaxPooling2D((2,2))(c2)\n","\n","    #   25 -> 12\n","    filters = 64\n","    c3 = Conv2D(filters, (3, 3), activation=None, padding=\"same\")(p2)\n","    c3 = residual_block(c3, filters)\n","    c3 = residual_block(c3, filters, batch_activate=True)\n","    p3 = MaxPooling2D((2,2))(c3)\n","\n","    #   12 -> 6\n","    filters = 128\n","    c4 = Conv2D(filters, (3, 3), activation=None, padding=\"same\")(p3)\n","    c4 = residual_block(c4, filters)\n","    c4 = residual_block(c4, filters, batch_activate=True)\n","    p4 = MaxPooling2D((2,2))(c4)\n","\n","    #  middle 6 -> 6\n","    filters = 256\n","    cm = Conv2D(filters, (3,3), activation=None, padding='same')(p4)\n","    cm = residual_block(cm, filters)\n","    cm = residual_block(cm, filters)\n","\n","    #   upsampling\n","    # 6 -> 12\n","    filters = 128\n","    u4 = Conv2DTranspose(filters, (3, 3), strides=(2, 2), padding=\"same\")(cm)\n","    u4 = concatenate([u4, c4])\n","\n","    u4 = Conv2D(filters, (3, 3), activation=None, padding=\"same\")(u4)\n","    u4 = residual_block(u4, filters)\n","    u4 = residual_block(u4, filters, batch_activate=True)\n","\n","    # 12 -> 25\n","    filters = 64\n","    u3 = Conv2DTranspose(filters, (3, 3), strides=(2, 2), padding=\"valid\")(c4)\n","    u3 = concatenate([u3, c3])\n","\n","    u3 = Conv2D(filters, (3, 3), activation=None, padding=\"same\")(u3)\n","    u3 = residual_block(u3, filters)\n","    u3 = residual_block(u3, filters, batch_activate=True)\n","\n","    # 25 -> 50\n","    filters = 32\n","    u2 = Conv2DTranspose(filters, (3, 3), strides=(2, 2), padding=\"same\")(c3)\n","    u2 = concatenate([u2, c2])\n","\n","    u2= Conv2D(filters, (3, 3), activation=None, padding=\"same\")(u2)\n","    u2 = residual_block(u2, filters)\n","    u2 = residual_block(u2, filters, batch_activate=True)\n","\n","    # 50 -> 101\n","    filters = 16\n","    u1 = Conv2DTranspose(filters, (3, 3), strides=(2, 2), padding=\"valid\")(c2)\n","    u1 = concatenate([u1, c1])\n","\n","    u1= Conv2D(filters, (3, 3), activation=None, padding=\"same\")(u1)\n","    u1 = residual_block(u1, filters)\n","    u1 = residual_block(u1, filters, batch_activate=True)\n","\n","    output_layer = Conv2D(1, (1,1), padding=\"same\")(u1)\n","\n","    model = Model(inputs, output_layer)\n","    return model\n","\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dJrgQlL_kB-s","colab_type":"code","colab":{}},"source":["def BatchActivate(x):\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    return x\n","\n","def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n","    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n","    if activation == True:\n","        x = BatchActivate(x)\n","    return x\n","\n","def residual_block(blockInput, num_filters=16, batch_activate = False):\n","    x = BatchActivate(blockInput)\n","    x = convolution_block(x, num_filters, (3,3) )\n","    x = convolution_block(x, num_filters, (3,3), activation=False)\n","    x = Add()([x, blockInput])\n","    if batch_activate:\n","        x = BatchActivate(x)\n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wtmSGSP5kB-u","colab_type":"code","colab":{}},"source":["def build_model(input_layer, start_neurons, DropoutRatio = 0.5):\n","    # 101 -> 50\n","    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(input_layer)\n","    conv1 = residual_block(conv1,start_neurons * 1)\n","    conv1 = residual_block(conv1,start_neurons * 1, True)\n","    pool1 = MaxPooling2D((2, 2))(conv1)\n","    pool1 = Dropout(DropoutRatio/2)(pool1)\n","\n","    # 50 -> 25\n","    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(pool1)\n","    conv2 = residual_block(conv2,start_neurons * 2)\n","    conv2 = residual_block(conv2,start_neurons * 2, True)\n","    pool2 = MaxPooling2D((2, 2))(conv2)\n","    pool2 = Dropout(DropoutRatio)(pool2)\n","\n","    # 25 -> 12\n","    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(pool2)\n","    conv3 = residual_block(conv3,start_neurons * 4)\n","    conv3 = residual_block(conv3,start_neurons * 4, True)\n","    pool3 = MaxPooling2D((2, 2))(conv3)\n","    pool3 = Dropout(DropoutRatio)(pool3)\n","\n","    # 12 -> 6\n","    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(pool3)\n","    conv4 = residual_block(conv4,start_neurons * 8)\n","    conv4 = residual_block(conv4,start_neurons * 8, True)\n","    pool4 = MaxPooling2D((2, 2))(conv4)\n","    pool4 = Dropout(DropoutRatio)(pool4)\n","\n","    # Middle\n","    convm = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(pool4)\n","    convm = residual_block(convm,start_neurons * 16)\n","    convm = residual_block(convm,start_neurons * 16, True)\n","    \n","    # 6 -> 12\n","    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n","    uconv4 = concatenate([deconv4, conv4])\n","    uconv4 = Dropout(DropoutRatio)(uconv4)\n","    \n","    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv4)\n","    uconv4 = residual_block(uconv4,start_neurons * 8)\n","    uconv4 = residual_block(uconv4,start_neurons * 8, True)\n","    \n","    # 12 -> 25\n","    #deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n","    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"valid\")(uconv4)\n","    uconv3 = concatenate([deconv3, conv3])    \n","    uconv3 = Dropout(DropoutRatio)(uconv3)\n","    \n","    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n","    uconv3 = residual_block(uconv3,start_neurons * 4)\n","    uconv3 = residual_block(uconv3,start_neurons * 4, True)\n","\n","    # 25 -> 50\n","    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n","    uconv2 = concatenate([deconv2, conv2])\n","        \n","    uconv2 = Dropout(DropoutRatio)(uconv2)\n","    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n","    uconv2 = residual_block(uconv2,start_neurons * 2)\n","    uconv2 = residual_block(uconv2,start_neurons * 2, True)\n","    \n","    # 50 -> 101\n","    #deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n","    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"valid\")(uconv2)\n","    uconv1 = concatenate([deconv1, conv1])\n","    \n","    uconv1 = Dropout(DropoutRatio)(uconv1)\n","    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n","    uconv1 = residual_block(uconv1,start_neurons * 1)\n","    uconv1 = residual_block(uconv1,start_neurons * 1, True)\n","    \n","    #uconv1 = Dropout(DropoutRatio/2)(uconv1)\n","    #output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n","    output_layer = Conv2D(1, (1,1), padding=\"same\", activation=None)(uconv1)\n","    \n","    \n","    return output_layer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"OYbR3X7rlXJv","colab":{}},"source":["epochs = 100\n","init_lr = 1e-2\n","K.clear_session()\n","sgd = SGD(lr=init_lr, momentum=0.9, decay=init_lr / epochs)\n","adam = Adam(lr=init_lr)\n","monitor = 'val_iou2'\n","monitor_mode = 'max'\n","model_callbacks = [\n","    EarlyStopping(monitor=monitor, mode=monitor_mode, patience=12, verbose=1),\n","    ReduceLROnPlateau(monitor=monitor, mode=monitor_mode, factor=0.1, patience=3, min_lr=1e-9, verbose=1)\n","]\n","\n","# model= unet_resnet_model()\n","input_layer = Input((101,101,1))\n","model = Model(input_layer, build_model(input_layer=input_layer, start_neurons=16))\n","model.compile(optimizer=adam, loss=lovasz_loss, metrics=[iou2])\n","print(len(model.layers))\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0vk4S8r6qM0p","colab_type":"code","colab":{}},"source":["model.save('/content/drive/My Drive/Kaggle/TGS-Salt-Segmentation/models/unet_resnet_101_adam_lovasz-loss_iou-metric.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"error","timestamp":1565694345105,"user_tz":-180,"elapsed":151763,"user":{"displayName":"Robert-George Colt","photoUrl":"","userId":"03778483518713272755"}},"id":"P6h_QZZRx4aS","outputId":"1911331e-1086-4108-8a35-d57a3c399428","colab":{"base_uri":"https://localhost:8080/","height":421}},"source":["model.fit(x_train, y_train, batch_size=32, epochs=100, validation_data=(x_valid, y_valid), callbacks=model_callbacks)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Train on 3200 samples, validate on 800 samples\n","Epoch 1/100\n","3200/3200 [==============================] - 65s 20ms/step - loss: 1.0864 - iou2: 0.2249 - val_loss: 1.1250 - val_iou2: 0.3500\n","Epoch 2/100\n","3200/3200 [==============================] - 53s 17ms/step - loss: 1.0073 - iou2: 0.2813 - val_loss: 1.0049 - val_iou2: 0.3900\n","Epoch 3/100\n","1472/3200 [============>.................] - ETA: 26s - loss: 1.0064 - iou2: 0.2878"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-25e8235ae188>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yO1vlnMt6CwS","colab":{}},"source":["!cd '/content/drive/My Drive/TGS-Salt-Segmentation'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"elapsed":2139,"status":"ok","timestamp":1565681856128,"user":{"displayName":"Robert-George Colt","photoUrl":"","userId":"03778483518713272755"},"user_tz":-180},"id":"r5R8t0MM6MwT","outputId":"a2f108bc-6e83-4433-fcfa-a6db75d6ac58","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!git status"],"execution_count":0,"outputs":[{"output_type":"stream","text":["fatal: not a git repository (or any of the parent directories): .git\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"dxsjJq4mjgUy"},"source":[""]}]}